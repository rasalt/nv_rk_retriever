{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with the Nemo Retriever \"Embedding\" microservice\n",
    "|rkharwar@nvidia.com| Author(s) | [Ruchika Kharwar](https://github.com/rasalt)\n",
    "\n",
    "NOTE: This notebook has been tested in the following environment:\n",
    "Python version = 3.10.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "<> \n",
    "\n",
    "## Objective\n",
    "This notebook aims to show you how to leverage a freshly deployed \"embedding micro-service\" with a python client. These examples aim to be building blocks of the larger solution you will likley have in place for yout Generative AI use case.\n",
    "\n",
    "## Before you begin\n",
    "### Set up your environment.\n",
    "Refer to page <> for details on how to deploy the service.\n",
    "You should have a docker service running namely \n",
    "\"embedding-ms\" on the port of your choice. \n",
    "For the purpose of this exercise this service was deployed on port 8080.\n",
    "\n",
    "eg. In my environment this service is running as \"embedding-ms-alone\" on port 8080\n",
    "7f8e5cb76cb2   nvcr.io/ohlfw0olaadg/ea-participants/nemo-retriever-embedding-microservice:24.02   \"/opt/nvidia/nvidia_â€¦\"   15 minutes ago   Up 15 minutes             0.0.0.0:8080->8080/tcp, :::8080->8080/tcp                                                                                                            embedding-ms-alone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the environment vairables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_URL = \"http://localhost:8080/v1\"\n",
    "MODEL_ID = \"NV-Embed-QA\"\n",
    "INPUT_TYPE = \"passage\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo_retriever.embedder_client import EmbedderClient\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = EmbedderClient(base_url=EMBEDDING_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object='list' data=[EmbeddingModel(id='NV-Embed-QA', object='model', created=0, owned_by='organization-owner', additional_properties={})] additional_properties={}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # GET models - list available embedding models\n",
    "    response = embedder.get_models()\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred while listing available embedding models:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The girl threw the butter out of the window to see 'butter-fly'.\"\n",
    "try:\n",
    "    # Note: When using the NV-Embed-QA and E5 models you should additionally specify the `input_type`\n",
    "    # If using other models such as GTE or GTR, the `input_type` argument does not need to be specified\n",
    "    response = embedder.create_embedding(input=text, model=\"NV-Embed-QA\", input_type=\"query\")\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred while creating an embedding:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Health checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # GET Health Check - check if service is live\n",
    "    response = embedder.health_check_is_live()\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred during health check (live):\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # GET Health Check - check if service is ready\n",
    "    response = embedder.health_check_is_ready()\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred during health check (ready):\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Tiny strides pave the way for monumental leaps.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
